{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import string\n",
    "import datasets\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence'],\n",
       "        num_rows: 42068\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence'],\n",
       "        num_rows: 3761\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence'],\n",
       "        num_rows: 3370\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = datasets.load_dataset(\"ptb_text_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos = {i:j for i,j in enumerate(\" \"+\".\"+\",\"+string.ascii_lowercase)}\n",
    "stoi = {j:i for i,j in itos.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\" \n",
    "Never forget what you are, for surely the world will not. Make it your strength. Then it can never be your weakness. Armour yourself in it, and it will never be used to hurt you.\n",
    "\"\"\".lower().strip()\n",
    "\n",
    "dataset = [(ch1, ch2) for ch1,ch2 in zip(text, text[1:])]\n",
    "X = torch.tensor([stoi[i[0]] for i in dataset])\n",
    "Y = torch.tensor([stoi[i[1]] for i in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "embed_dim = 2\n",
    "hidden_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, embed_dim=2, vocab_size=29, hidden_size=10):\n",
    "        super().__init__()\n",
    "        # embedding\n",
    "        self.C = torch.rand((len(stoi), hidden_size))\n",
    "\n",
    "        # intial layer\n",
    "        # self.W_xi = torch.rand(embed_dim, hidden_size)\n",
    "        # self.b_xi = torch.rand(hidden_size)\n",
    "\n",
    "        # weights for reccurent loop\n",
    "        self.W_xh = torch.rand(hidden_size, hidden_size)\n",
    "        self.b_xh = torch.rand(hidden_size)\n",
    "\n",
    "        # hidden state\n",
    "        self.h = torch.rand(hidden_size)\n",
    "        self.W_hh = torch.rand(hidden_size, hidden_size)\n",
    "\n",
    "        # classification head\n",
    "        self.W_hy = torch.rand(hidden_size, vocab_size)\n",
    "        self.b_hy = torch.rand(vocab_size)\n",
    "\n",
    "        self.params = [self.W_xh, self.b_xh, self.W_hh, self.W_hy, self.b_hy]\n",
    "        \n",
    "    def step(self, x):\n",
    "\n",
    "        h_out = self.h @ self.W_hh\n",
    "        x_out = x @ self.W_xh + self.b_xh\n",
    "\n",
    "        # this is a new hidden state\n",
    "        return torch.tanh(x_out+h_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # embed\n",
    "        x = self.C[x]\n",
    "        # x = torch.tanh(x @ self.W_xi + self.b_xi)\n",
    "        \n",
    "        self.h = self.step(x)\n",
    "\n",
    "        return self.h @ self.W_hy + self.b_hy\n",
    "\n",
    "rnn = RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = rnn(X[1])\n",
    "probas = F.softmax(logits, dim=-1)\n",
    "_, indx = torch.topk(probas, 1)\n",
    "itos[indx.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my rnn\n",
    "# embeddings\n",
    "torch.manual_seed(42)\n",
    "C = torch.rand((len(stoi), embed_dim)) # N, E\n",
    "embeds = C[X] # N, E\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
